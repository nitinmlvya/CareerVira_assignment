{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc0</td>\n",
       "      <td>Last updated: 12 April 2020</td>\n",
       "      <td>LAST_UPDATED_DATE</td>\n",
       "      <td>Drupal.org Privacy Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc0</td>\n",
       "      <td>We value your privacy and strive to protect yo...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Drupal.org Privacy Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc0</td>\n",
       "      <td>(2) [p] Disclaimer: This summary is not itself...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Drupal.org Privacy Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Readable Summary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc0</td>\n",
       "      <td>Right to be Informed - A data subject has the ...</td>\n",
       "      <td>PERSONAL_DATA_RIGHTS</td>\n",
       "      <td>Drupal.org Privacy Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Readable Summary</td>\n",
       "      <td>Rights of the Data Subject</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc0</td>\n",
       "      <td>Right to Restrict Processing - A data subject ...</td>\n",
       "      <td>PERSONAL_DATA_RIGHTS</td>\n",
       "      <td>Drupal.org Privacy Policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human Readable Summary</td>\n",
       "      <td>Rights of the Data Subject</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                                               text  \\\n",
       "0   doc0                        Last updated: 12 April 2020   \n",
       "1   doc0  We value your privacy and strive to protect yo...   \n",
       "2   doc0  (2) [p] Disclaimer: This summary is not itself...   \n",
       "3   doc0  Right to be Informed - A data subject has the ...   \n",
       "4   doc0  Right to Restrict Processing - A data subject ...   \n",
       "\n",
       "                  class                         h1   h2  \\\n",
       "0     LAST_UPDATED_DATE  Drupal.org Privacy Policy  NaN   \n",
       "1               UNKNOWN  Drupal.org Privacy Policy  NaN   \n",
       "2               UNKNOWN  Drupal.org Privacy Policy  NaN   \n",
       "3  PERSONAL_DATA_RIGHTS  Drupal.org Privacy Policy  NaN   \n",
       "4  PERSONAL_DATA_RIGHTS  Drupal.org Privacy Policy  NaN   \n",
       "\n",
       "                       h3                          h4   h5  \n",
       "0                     NaN                         NaN  NaN  \n",
       "1                     NaN                         NaN  NaN  \n",
       "2  Human Readable Summary                         NaN  NaN  \n",
       "3  Human Readable Summary  Rights of the Data Subject  NaN  \n",
       "4  Human Readable Summary  Rights of the Data Subject  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2348, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doc_id       0\n",
       "text         0\n",
       "class        0\n",
       "h1         574\n",
       "h2        1360\n",
       "h3        1337\n",
       "h4        2043\n",
       "h5        2252\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNKNOWN                            428\n",
       "PERSONAL_DATA_USES                 271\n",
       "THIRDPARTY_INFORMATION_SHARING     246\n",
       "PERSONAL_DATA_WE_COLLECT           245\n",
       "PERSONAL_DATA_RIGHTS               201\n",
       "COOKIES_AND_TRACKING_TECHNOLOGY    192\n",
       "JURISDICTION                       176\n",
       "HOW_WE_COLLECT_PERSONAL_DATA       133\n",
       "CONTACT                            124\n",
       "SECURITY                           101\n",
       "UPDATES_AND_NOTIFICATIONS           66\n",
       "LAST_UPDATED_DATE                   50\n",
       "CHILDREN                            50\n",
       "MARKETING_OPT_OUT                   37\n",
       "DO_NOT_TRACK                        28\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "df['h1'] = df['h1'].str.lower()\n",
    "df['h2'] = df['h2'].str.lower()\n",
    "df['h3'] = df['h3'].str.lower()\n",
    "df['h4'] = df['h4'].str.lower()\n",
    "df['h5'] = df['h5'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(r\"(\\(\\d+\\))\", '')\n",
    "df['text'] = df['text'].str.replace(r\"(\\[[a-zA-Z]+\\])\", '')\n",
    "df['text'] = df['text'].str.replace(r\"|\", ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc0</td>\n",
       "      <td>last updated: 12 april 2020</td>\n",
       "      <td>LAST_UPDATED_DATE</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc0</td>\n",
       "      <td>we value your privacy and strive to protect yo...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                                               text  \\\n",
       "0   doc0                        last updated: 12 april 2020   \n",
       "1   doc0  we value your privacy and strive to protect yo...   \n",
       "\n",
       "               class                         h1   h2   h3   h4   h5  \n",
       "0  LAST_UPDATED_DATE  drupal.org privacy policy  NaN  NaN  NaN  NaN  \n",
       "1            UNKNOWN  drupal.org privacy policy  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import  Dropout, Dense, Embedding, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = df[['text', 'h1', 'h2', 'h3', 'h4', 'h5']].apply(\n",
    "    lambda x: ' '.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "## for word embedding\n",
    "import gensim\n",
    "import gensim.downloader as gensim_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess a string.\n",
    ":parameter\n",
    "    :param text: string - name of column containing text\n",
    "    :param lst_stopwords: list - list of stopwords to remove\n",
    "    :param flg_stemm: bool - whether stemming is to be applied\n",
    "    :param flg_lemm: bool - whether lemmitisation is to be applied\n",
    ":return\n",
    "    cleaned text\n",
    "'''\n",
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and   \n",
    "    ## characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "lst_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc0</td>\n",
       "      <td>last updated: 12 april 2020</td>\n",
       "      <td>LAST_UPDATED_DATE</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>last updated 12 april 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc0</td>\n",
       "      <td>we value your privacy and strive to protect yo...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>value privacy strive protect personal informat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc0</td>\n",
       "      <td>disclaimer: this summary is not itself a par...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human readable summary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>disclaimer summary part privacy policy legal d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc0</td>\n",
       "      <td>right to be informed - a data subject has the ...</td>\n",
       "      <td>PERSONAL_DATA_RIGHTS</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human readable summary</td>\n",
       "      <td>rights of the data subject</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right informed data subject right know whether...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc0</td>\n",
       "      <td>right to restrict processing - a data subject ...</td>\n",
       "      <td>PERSONAL_DATA_RIGHTS</td>\n",
       "      <td>drupal.org privacy policy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>human readable summary</td>\n",
       "      <td>rights of the data subject</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right restrict processing data subject right r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id                                               text  \\\n",
       "0   doc0                        last updated: 12 april 2020   \n",
       "1   doc0  we value your privacy and strive to protect yo...   \n",
       "2   doc0    disclaimer: this summary is not itself a par...   \n",
       "3   doc0  right to be informed - a data subject has the ...   \n",
       "4   doc0  right to restrict processing - a data subject ...   \n",
       "\n",
       "                  class                         h1   h2  \\\n",
       "0     LAST_UPDATED_DATE  drupal.org privacy policy  NaN   \n",
       "1               UNKNOWN  drupal.org privacy policy  NaN   \n",
       "2               UNKNOWN  drupal.org privacy policy  NaN   \n",
       "3  PERSONAL_DATA_RIGHTS  drupal.org privacy policy  NaN   \n",
       "4  PERSONAL_DATA_RIGHTS  drupal.org privacy policy  NaN   \n",
       "\n",
       "                       h3                          h4   h5  \\\n",
       "0                     NaN                         NaN  NaN   \n",
       "1                     NaN                         NaN  NaN   \n",
       "2  human readable summary                         NaN  NaN   \n",
       "3  human readable summary  rights of the data subject  NaN   \n",
       "4  human readable summary  rights of the data subject  NaN   \n",
       "\n",
       "                                          text_clean  \n",
       "0                         last updated 12 april 2020  \n",
       "1  value privacy strive protect personal informat...  \n",
       "2  disclaimer summary part privacy policy legal d...  \n",
       "3  right informed data subject right know whether...  \n",
       "4  right restrict processing data subject right r...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[\"text\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "          lst_stopwords=lst_stopwords))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df[\"text_clean\"]\n",
    "\n",
    "## create list of lists of unigrams\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "    lst_words = string.split()\n",
    "    lst_grams = [\" \".join(lst_words[i:i+1]) \n",
    "               for i in range(0, len(lst_words), 1)]\n",
    "    lst_corpus.append(lst_grams)\n",
    "\n",
    "## detect bigrams and trigrams\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, \n",
    "                 delimiter=\" \".encode(), min_count=5, threshold=10)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
    "            delimiter=\" \".encode(), min_count=5, threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
    "\n",
    "## fit w2v\n",
    "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, size=300,   \n",
    "            window=8, min_count=1, sg=1, iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word = \"data\"\n",
    "# nlp[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2348, 300)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import preprocessing as kprocessing\n",
    "from keras import backend as K\n",
    "\n",
    "## tokenize text\n",
    "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
    "                     oov_token=\"NaN\", \n",
    "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(lst_corpus)\n",
    "dic_vocabulary = tokenizer.word_index\n",
    "## create sequence\n",
    "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
    "## padding sequence\n",
    "X = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
    "                    maxlen=300, padding=\"post\", truncating=\"post\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "## start the matrix (length of vocabulary x vector size) with all 0s\n",
    "embeddings = np.zeros((len(dic_vocabulary)+1, 300))\n",
    "\n",
    "for word,idx in dic_vocabulary.items():\n",
    "    ## update the row with vector\n",
    "    try:\n",
    "        embeddings[idx] =  nlp[word]\n",
    "    ## if word not in model then skip and the row stays all 0s\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.text import one_hot\n",
    "\n",
    "# vocab_size = 500\n",
    "# X = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ') for d in all_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max_length = 300\n",
    "# X = pad_sequences(X, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2348, 15)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes one hot\n",
    "n_classes = y.nunique()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_vec = label_encoder.fit_transform(y)\n",
    "\n",
    "y = to_categorical(y_vec, num_classes=n_classes)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1573, 775, 1573, 775)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shape = X_train.shape[1]\n",
    "# shape =  vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, verbose=1)\n",
    "\n",
    "# predicted = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 300, 300)     1454100     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 300, 300)     0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 300, 300)     90300       permute_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention (Permute)             (None, 300, 300)     0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 300, 300)     0           embedding_12[0][0]               \n",
      "                                                                 attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 300, 600)     1442400     multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 600)          2162400     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 64)           38464       bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 15)           975         dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,188,639\n",
      "Trainable params: 3,734,539\n",
      "Non-trainable params: 1,454,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "## code attention layer\n",
    "def attention_layer(inputs, neurons):\n",
    "    x = layers.Permute((2,1))(inputs)\n",
    "    x = layers.Dense(neurons, activation=\"softmax\")(x)\n",
    "    x = layers.Permute((2,1), name=\"attention\")(x)\n",
    "    x = layers.multiply([inputs, x])\n",
    "    return x\n",
    "\n",
    "## input\n",
    "x_in = layers.Input(shape=(300,))\n",
    "## embedding\n",
    "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
    "                     output_dim=embeddings.shape[1], \n",
    "                     weights=[embeddings],\n",
    "                     input_length=300, trainable=False)(x_in)\n",
    "## apply attention\n",
    "x = attention_layer(x, neurons=300)\n",
    "## 2 layers of bidirectional lstm\n",
    "x = layers.Bidirectional(layers.LSTM(units=300, dropout=0.2, \n",
    "                         return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(units=300, dropout=0.2))(x)\n",
    "## final dense layers\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "y_out = layers.Dense(15, activation='softmax')(x)\n",
    "## compile\n",
    "model = models.Model(x_in, y_out)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1573 samples, validate on 775 samples\n",
      "Epoch 1/100\n",
      "1573/1573 [==============================] - 353s 225ms/step - loss: 2.5879 - acc: 0.1774 - val_loss: 2.4880 - val_acc: 0.1819\n",
      "Epoch 2/100\n",
      "1573/1573 [==============================] - 318s 202ms/step - loss: 2.4853 - acc: 0.1825 - val_loss: 2.4796 - val_acc: 0.1819\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-4c1901f28166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
